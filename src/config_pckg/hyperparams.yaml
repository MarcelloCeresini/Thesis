training:
  lr: 0.001
  weight_decay: 0.001
  n_epochs: 500
  patience_reduce_lr: 15
  patience_end_training: 50
  min_lr: 0.0000001
  batch_size: 8

val:
  batch_size: 8
  n_epochs_val: 5

loss: MSE_loss