name: EncodeProcessDecode_Baseline
encoder:
  type: sequential_model
  layers: 
    - {type: layer, name: Linear, out_features: 32}
    - {type: layer, name: LeakyReLU}
    # Last layer to get out_channels = message_passer["out_channels"] is automatic
bc_encoder:
  type: repeated_shared_layer
  repeats_training: 5
  name: Simple_MLPConv
  out_channels: 32 # also in_channels are the same, to be able to call multiple times
  mid_channels: 32
  attention: True
  add_global_info: False
  add_BC_info: False
  skip: True
  aggr: mean
  nn: # takes as input edge_features (and does NOT update them, always gets edge features)
    type: sequential_model
    layers: 
      - {type: layer, name: Linear, out_features: 32}
      - {type: layer, name: LeakyReLU}
      # Last (Linear) layer for internal_mlp is always added autonomously
  nn_update:
    type: sequential_model
    layers: 
      - {type: layer, name: Linear, out_features: 32}
      - {type: layer, name: LeakyReLU}
message_passer:
  type: repeated_shared_layer
  repeats_training: 5
  name: Simple_MLPConv # [NNConv, GCNConv, MLPConv, Simple_MLPConv_edges]
  out_channels: 32 # also in_channels are the same, to be able to call multiple times
  mid_channels: 32
  attention: True
  k_heads: 16
  add_global_info: True
  add_BC_info: True
  skip: True
  aggr: mean
  nn: # takes as input edge_features (and does NOT update them, always gets edge features)
    type: sequential_model
    layers: 
      - {type: layer, name: Linear, out_features: 32}
      - {type: layer, name: LeakyReLU}
      # Last (Linear) layer for internal_mlp is always added autonomously
  nn_update:
    type: sequential_model
    layers: 
      - {type: layer, name: Linear, out_features: 32}
      - {type: layer, name: LeakyReLU}

decoder:
  type: sequential_model
  layers: 
    - {type: layer, name: Linear, out_features: 32}
    - {type: layer, name: LeakyReLU}
    # Last (Linear) layer for regression is always added by model autonomously

