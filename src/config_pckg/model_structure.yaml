name: EncodeProcessDecode_Baseline
encoder:
  type: sequential_model
  layers: 
    - {type: layer, name: Linear, out_features: 32}
    - {type: layer, name: ReLU}
    # Last layer to get out_channels = message_passer["out_channels"] is automatic
message_passer:
  type: repeated_shared_layer
  repeats_training: 10
  name: MLPConv_plus_global # [NNConv, GCNConv, MLPConv, MLPConv_plus_global]
  out_channels: 64 # also in_channels are the same, to be able to call multiple times
  mid_channels: 32
  aggr: sum
  nn: # takes as input edge_features (and does NOT update them, always gets edge features)
    type: sequential_model
    layers: 
      - {type: layer, name: Linear, out_features: 16}
      - {type: layer, name: ReLU}
      # Last (Linear) layer for internal_mlp is always added autonomously
decoder:
  type: sequential_model
  layers: 
    - {type: layer, name: Linear, out_features: 16}
    - {type: layer, name: ReLU}
    # Last (Linear) layer for regression is always added by model autonomously

